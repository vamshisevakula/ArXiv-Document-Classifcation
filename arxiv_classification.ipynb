{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVC_Tarun_multi-model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gZgqppq0DGU",
        "outputId": "ccb24ad9-60cc-4ed6-a757-b7562b303d67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!ls '/content/drive/Shared drives/ADA_assignment_2/A2_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "abstracts_Vocab.txt\t\t  encoded_data.pickle\n",
            "arxiv-metadata-oai-snapshot.json  hyperparameter_data\n",
            "clean_balanced_train_data.csv\t  models\n",
            "clean_full_train_data.csv\t  Predictions\n",
            "clean_test_data.csv\t\t  test_data.csv\n",
            "encoded_data_450k.pickle\t  train_data_labels.csv\n",
            "encoded_data_500k.pickle\t  word2vec\n",
            "encoded_data_balanced.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHkIYQHbqqjs"
      },
      "source": [
        "### Library load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vOqWRjCkUe1"
      },
      "source": [
        "# Loading necessary Libraries\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLZY_WKKqtVM"
      },
      "source": [
        "### Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTsbGwedz0FI",
        "outputId": "a7546a71-d0b0-42c7-9485-ef22187ac07a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/Shared drives/ADA_assignment_2/A2_data/train_data_labels.csv', usecols = ['label', 'abstract'])\n",
        "train_df.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>save for some special cases, current training ...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we consider a dynamical system with finitely m...</td>\n",
              "      <td>math.DS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we consider discrete dynamical systems of \"ant...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>retrofitting techniques, which inject external...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>approaches to decision-making under uncertaint...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            abstract    label\n",
              "0  save for some special cases, current training ...       cs\n",
              "1  we consider a dynamical system with finitely m...  math.DS\n",
              "2  we consider discrete dynamical systems of \"ant...       cs\n",
              "3  retrofitting techniques, which inject external...       cs\n",
              "4  approaches to decision-making under uncertaint...       cs"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpgfwshq6Lpr",
        "outputId": "0b9642d5-3e80-4e20-a6fe-44a181e10437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df.dropna(inplace = True) # Drop any null values in data\n",
        "train_df = train_df.drop_duplicates(subset=['abstract'], keep = False) # Drop the duplicate abstracts with multiple labels per abstract\n",
        "train_df = train_df.reset_index(drop = True) # Reset index for better access of rows\n",
        "train_df.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19746, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsfUcF-u4FU4",
        "outputId": "a3a45fd9-5eac-4b5f-e065-5efb0fb88783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Check the data balance with labels\n",
        "df1 = train_df['label'].value_counts().reset_index()\n",
        "df1"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cs</td>\n",
              "      <td>8438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>math.AG</td>\n",
              "      <td>818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>math.CO</td>\n",
              "      <td>657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>astro-ph.HE</td>\n",
              "      <td>623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>math.AP</td>\n",
              "      <td>560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>physics.pop-ph</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>nlin.CG</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>physics.atm-clus</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>stat.OT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>math.ST</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               index  label\n",
              "0                 cs   8438\n",
              "1            math.AG    818\n",
              "2            math.CO    657\n",
              "3        astro-ph.HE    623\n",
              "4            math.AP    560\n",
              "..               ...    ...\n",
              "95    physics.pop-ph      3\n",
              "96           nlin.CG      3\n",
              "97  physics.atm-clus      2\n",
              "98           stat.OT      2\n",
              "99           math.ST      1\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FRtX7CTF9Qm",
        "outputId": "df49e09f-b296-421b-869e-dc96e3ab982f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(set(train_df['label']))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5sSSH3sq5hg"
      },
      "source": [
        "### Text Pre-processing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI57NdEWDcIU",
        "outputId": "e50dfdd4-26f1-4ca4-b9d5-d64532ab2234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def preprocessing(all_abstracts):\n",
        "\n",
        "    \"\"\"\n",
        "    Take in an array of abstracts, and return the processed abstracts by performing a series of steps\n",
        "    \"\"\"\n",
        "\n",
        "    processed_abstracts = []\n",
        "\n",
        "    for abstract in tqdm(all_abstracts):\n",
        "\n",
        "        # remove other non-alphabets tokens (i.e. keep only alphabets and whitespaces).\n",
        "        abstract = re.sub('[^a-zA-Z ]', '', abstract)\n",
        "\n",
        "        # convert to lowercase\n",
        "        abstract_lower = abstract.lower()\n",
        "\n",
        "        # remove URLs\n",
        "        abstract_no_url = re.compile(r'https?://\\S+|www\\.\\S+').sub(r'', abstract_lower)\n",
        "\n",
        "        # remove HTML tags\n",
        "        abstract_no_html = re.compile(r'<[^>]*>').sub(r'', abstract_no_url)\n",
        "\n",
        "        # replace the digits with space\n",
        "        abstract_no_digit = re.sub(r'[^\\D\\s]', ' ', abstract_no_html)\n",
        "\n",
        "        # remove punctuation\n",
        "        # these are the punctuations supplied by python by default - !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n",
        "        \n",
        "        abstract_no_punctuations = ' '.join(re.sub(r'[^\\w\\s]', ' ', abstract_no_digit).split())\n",
        "        abstract_no_punctuations = abstract_no_punctuations.replace('_', ' ')\n",
        "\n",
        "        # Stop Words Removal\n",
        "        STOPWORDS = set(stopwords.words('english'))\n",
        "        abstract_no_stopwords = \" \".join([word for word in str(abstract_no_punctuations).split() if word not in STOPWORDS])\n",
        "\n",
        "        # Stemming\n",
        "        # stemmer = PorterStemmer()\n",
        "        # abstract_stemmed = \" \".join([stemmer.stem(word) for word in abstract_no_stopwords.split()])\n",
        "\n",
        "        # Lemmatizer with POS tagging\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
        "        pos_tagged_text = nltk.pos_tag(abstract_no_stopwords.split())\n",
        "        abstract_lemmatized = \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
        "\n",
        "        processed = abstract_lemmatized\n",
        "\n",
        "        words = processed.split()\n",
        "\n",
        "        # keep words that have length of more than 1 (e.g. gb, bb), remove those with length 1.\n",
        "        processed_abstracts.append(' '.join([word for word in words if len(word) > 1]))\n",
        "\n",
        "    return processed_abstracts # return list of processed abstracts"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWSIxyqUDbtP",
        "outputId": "e00cf21b-7ccb-4afe-f9f4-211bec5f63d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df['processed_abstract'] = preprocessing(train_df['abstract']) # Pre-process raw abstracts"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19746/19746 [02:12<00:00, 149.08it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fkDLluTtCDk",
        "outputId": "dc790339-31fb-4bdf-b664-bdbf49109378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Generation of inner and outer labels for Hierarchical modelling\n",
        "label_outer = []\n",
        "label_inner = []\n",
        "\n",
        "for ix, row in train_df.iterrows():\n",
        "    label = row['label']\n",
        "    label_splits = label.split('.') # Split actual label into 2 parts\n",
        "    \n",
        "    if len(label_splits) == 2:\n",
        "        label_outer.append(label_splits[0]) # Append the high-level label into label_outer\n",
        "        label_inner.append(label_splits[1]) # Append the sub-level label into label_inner\n",
        "    else: # Handle 'cs' seperately\n",
        "        label_outer.append(label_splits[0]) # Append the high-level label into label_outer\n",
        "        label_inner.append('Nan') # Since no sub-levels for 'cs'\n",
        "        \n",
        "train_df['label_outer'] = label_outer\n",
        "train_df['label_inner'] = label_inner\n",
        "\n",
        "train_df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>label</th>\n",
              "      <th>processed_abstract</th>\n",
              "      <th>label_outer</th>\n",
              "      <th>label_inner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>save for some special cases, current training ...</td>\n",
              "      <td>cs</td>\n",
              "      <td>save special case current training method gene...</td>\n",
              "      <td>cs</td>\n",
              "      <td>Nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we consider a dynamical system with finitely m...</td>\n",
              "      <td>math.DS</td>\n",
              "      <td>consider dynamical system finitely many equili...</td>\n",
              "      <td>math</td>\n",
              "      <td>DS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we consider discrete dynamical systems of \"ant...</td>\n",
              "      <td>cs</td>\n",
              "      <td>consider discrete dynamical system ant like ag...</td>\n",
              "      <td>cs</td>\n",
              "      <td>Nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>retrofitting techniques, which inject external...</td>\n",
              "      <td>cs</td>\n",
              "      <td>retrofit technique inject external resource wo...</td>\n",
              "      <td>cs</td>\n",
              "      <td>Nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>approaches to decision-making under uncertaint...</td>\n",
              "      <td>cs</td>\n",
              "      <td>approach decision make uncertainty belief func...</td>\n",
              "      <td>cs</td>\n",
              "      <td>Nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19741</th>\n",
              "      <td>with the powerful deep network architectures, ...</td>\n",
              "      <td>cs</td>\n",
              "      <td>powerful deep network architecture generative ...</td>\n",
              "      <td>cs</td>\n",
              "      <td>Nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19742</th>\n",
              "      <td>we develop a mixed-characteristic version of t...</td>\n",
              "      <td>math.AG</td>\n",
              "      <td>develop mixed characteristic version mori muka...</td>\n",
              "      <td>math</td>\n",
              "      <td>AG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19743</th>\n",
              "      <td>in complex analysis, the winding number measur...</td>\n",
              "      <td>cs</td>\n",
              "      <td>complex analysis wind number measure number ti...</td>\n",
              "      <td>cs</td>\n",
              "      <td>Nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19744</th>\n",
              "      <td>we discuss secure computation of modular sum w...</td>\n",
              "      <td>cs</td>\n",
              "      <td>discuss secure computation modular sum multipl...</td>\n",
              "      <td>cs</td>\n",
              "      <td>Nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19745</th>\n",
              "      <td>in this paper, we define the notion of graph t...</td>\n",
              "      <td>math.AG</td>\n",
              "      <td>paper define notion graph trace kernel general...</td>\n",
              "      <td>math</td>\n",
              "      <td>AG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19746 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                abstract  ... label_inner\n",
              "0      save for some special cases, current training ...  ...         Nan\n",
              "1      we consider a dynamical system with finitely m...  ...          DS\n",
              "2      we consider discrete dynamical systems of \"ant...  ...         Nan\n",
              "3      retrofitting techniques, which inject external...  ...         Nan\n",
              "4      approaches to decision-making under uncertaint...  ...         Nan\n",
              "...                                                  ...  ...         ...\n",
              "19741  with the powerful deep network architectures, ...  ...         Nan\n",
              "19742  we develop a mixed-characteristic version of t...  ...          AG\n",
              "19743  in complex analysis, the winding number measur...  ...         Nan\n",
              "19744  we discuss secure computation of modular sum w...  ...         Nan\n",
              "19745  in this paper, we define the notion of graph t...  ...          AG\n",
              "\n",
              "[19746 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vefpiam8tIai",
        "outputId": "7123f017-4b6f-47d1-fcbd-fb3246c6fcc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Generate indexing labels for Level-1 classifier\n",
        "train_df1 = train_df[['label_outer', 'processed_abstract']]\n",
        "train_df1.loc[:,('label_id')] = train_df1['label_outer'].factorize()[0] # Factorise to get label-encodings of outer-label\n",
        "label_id_df = train_df1[['label_outer', 'label_id']].drop_duplicates().sort_values('label_id')\n",
        "label_to_id = dict(label_id_df.values) # Generate a look-up dictionary to get the labels from predictions\n",
        "id_to_label_outer = dict(label_id_df[['label_id', 'label_outer']].values)\n",
        "id_to_label_outer"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[key] = _infer_fill_value(value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'cs',\n",
              " 1: 'math',\n",
              " 2: 'q-fin',\n",
              " 3: 'cond-mat',\n",
              " 4: 'astro-ph',\n",
              " 5: 'q-bio',\n",
              " 6: 'physics',\n",
              " 7: 'stat',\n",
              " 8: 'nlin'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ouC6-BPtLZ1",
        "outputId": "8a75b8be-2f8a-4a87-d0cf-e65b0a87c47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_df1 # To be used for Level-1 model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label_outer</th>\n",
              "      <th>processed_abstract</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cs</td>\n",
              "      <td>save special case current training method gene...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>math</td>\n",
              "      <td>consider dynamical system finitely many equili...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cs</td>\n",
              "      <td>consider discrete dynamical system ant like ag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cs</td>\n",
              "      <td>retrofit technique inject external resource wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cs</td>\n",
              "      <td>approach decision make uncertainty belief func...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19741</th>\n",
              "      <td>cs</td>\n",
              "      <td>powerful deep network architecture generative ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19742</th>\n",
              "      <td>math</td>\n",
              "      <td>develop mixed characteristic version mori muka...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19743</th>\n",
              "      <td>cs</td>\n",
              "      <td>complex analysis wind number measure number ti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19744</th>\n",
              "      <td>cs</td>\n",
              "      <td>discuss secure computation modular sum multipl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19745</th>\n",
              "      <td>math</td>\n",
              "      <td>paper define notion graph trace kernel general...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19746 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label_outer                                 processed_abstract  label_id\n",
              "0              cs  save special case current training method gene...         0\n",
              "1            math  consider dynamical system finitely many equili...         1\n",
              "2              cs  consider discrete dynamical system ant like ag...         0\n",
              "3              cs  retrofit technique inject external resource wo...         0\n",
              "4              cs  approach decision make uncertainty belief func...         0\n",
              "...           ...                                                ...       ...\n",
              "19741          cs  powerful deep network architecture generative ...         0\n",
              "19742        math  develop mixed characteristic version mori muka...         1\n",
              "19743          cs  complex analysis wind number measure number ti...         0\n",
              "19744          cs  discuss secure computation modular sum multipl...         0\n",
              "19745        math  paper define notion graph trace kernel general...         1\n",
              "\n",
              "[19746 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM8MBBhdBJch"
      },
      "source": [
        "# Generate index labels for Level-2 models\n",
        "# Also generate multiple dataframes for every class\n",
        "id_to_label_inner = {}\n",
        "train_df2 = {}\n",
        "for label_code, label_outer in id_to_label_outer.items():\n",
        "    if label_outer == 'cs':\n",
        "        continue\n",
        "#     print(label_outer)\n",
        "    \n",
        "    temp_df = train_df[train_df['label_outer'] == label_outer].reset_index(drop = True)\n",
        "    \n",
        "    temp_df = temp_df[['label_inner', 'processed_abstract']]\n",
        "    temp_df.loc[:,('label_id')] = temp_df['label_inner'].factorize()[0] # Factorise to get label-encodings of inner-label\n",
        "    label_id_df = temp_df[['label_inner', 'label_id']].drop_duplicates().sort_values('label_id')\n",
        "    label_to_id = dict(label_id_df.values) # Generate a look-up dictionary to get the labels from predictions\n",
        "    id_to_label = dict(label_id_df[['label_id', 'label_inner']].values)\n",
        "    id_to_label_inner[label_outer] = id_to_label\n",
        "    train_df2[label_outer] = temp_df\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NepPqYdCBIki",
        "outputId": "50c73a40-2ba3-437d-c34f-f1094b05d533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "id_to_label_inner['math']"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'DS',\n",
              " 1: 'LO',\n",
              " 2: 'CO',\n",
              " 3: 'OA',\n",
              " 4: 'NT',\n",
              " 5: 'FA',\n",
              " 6: 'AP',\n",
              " 7: 'RT',\n",
              " 8: 'AG',\n",
              " 9: 'AC',\n",
              " 10: 'IT',\n",
              " 11: 'CA',\n",
              " 12: 'GT',\n",
              " 13: 'SG',\n",
              " 14: 'DG',\n",
              " 15: 'AT',\n",
              " 16: 'GR',\n",
              " 17: 'CT',\n",
              " 18: 'RA',\n",
              " 19: 'KT',\n",
              " 20: 'OC',\n",
              " 21: 'MG',\n",
              " 22: 'HO',\n",
              " 23: 'PR',\n",
              " 24: 'CV',\n",
              " 25: 'MP',\n",
              " 26: 'NA',\n",
              " 27: 'QA',\n",
              " 28: 'GN',\n",
              " 29: 'GM',\n",
              " 30: 'SP',\n",
              " 31: 'ST'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaiaYNg_BH31",
        "outputId": "7ed51b3e-36f4-4d42-eed6-08950fc366c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_df2['math'] # To be used by Level-2 models based on the label from Level-1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label_inner</th>\n",
              "      <th>processed_abstract</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DS</td>\n",
              "      <td>consider dynamical system finitely many equili...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LO</td>\n",
              "      <td>investigate correspondence complexity hierarch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CO</td>\n",
              "      <td>let ge fix constant let mathcal uniform regula...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OA</td>\n",
              "      <td>show large class countable discrete group sati...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CO</td>\n",
              "      <td>generalize two main theorem match polynomial u...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4643</th>\n",
              "      <td>DG</td>\n",
              "      <td>aim paper investigate uniqueness conic constan...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4644</th>\n",
              "      <td>AP</td>\n",
              "      <td>show knowledge dirichlet neumann map rough del...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4645</th>\n",
              "      <td>DG</td>\n",
              "      <td>paper prove compact manifold einstein metric p...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4646</th>\n",
              "      <td>AG</td>\n",
              "      <td>develop mixed characteristic version mori muka...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4647</th>\n",
              "      <td>AG</td>\n",
              "      <td>paper define notion graph trace kernel general...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4648 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label_inner                                 processed_abstract  label_id\n",
              "0             DS  consider dynamical system finitely many equili...         0\n",
              "1             LO  investigate correspondence complexity hierarch...         1\n",
              "2             CO  let ge fix constant let mathcal uniform regula...         2\n",
              "3             OA  show large class countable discrete group sati...         3\n",
              "4             CO  generalize two main theorem match polynomial u...         2\n",
              "...          ...                                                ...       ...\n",
              "4643          DG  aim paper investigate uniqueness conic constan...        14\n",
              "4644          AP  show knowledge dirichlet neumann map rough del...         6\n",
              "4645          DG  paper prove compact manifold einstein metric p...        14\n",
              "4646          AG  develop mixed characteristic version mori muka...         8\n",
              "4647          AG  paper define notion graph trace kernel general...         8\n",
              "\n",
              "[4648 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGK_Ea4rCYw0"
      },
      "source": [
        "del train_df # Free-up memory"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkKowuE5tkYG"
      },
      "source": [
        "#Generate TFIDF with best custom parameters based on multiple testing\n",
        "tfidf = TfidfVectorizer(encoding='utf-8',\n",
        "                        stop_words=None,\n",
        "                        lowercase=False,\n",
        "                        max_df=0.3,\n",
        "                        min_df=10,\n",
        "                        max_features=20000, \n",
        "                        norm='l2',\n",
        "                        sublinear_tf=True)\n",
        "\n",
        "tfidf_X = tfidf.fit_transform(train_df1['processed_abstract']).toarray() # Fit and transform the processed abstract"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGzChG3fuUAJ"
      },
      "source": [
        "# Perform a 80-20 split on train-data\n",
        "train_x, test_x, train_y, test_y = train_test_split(tfidf_X, \n",
        "                                                   train_df1['label_id'],\n",
        "                                                   test_size=0.2,\n",
        "                                                   random_state=11)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vORazfC6umJd",
        "outputId": "859a283b-9794-46a5-d2ce-f853c03c0146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the SVM model on the train and test split\n",
        "np.random.seed(42)\n",
        "SVM = svm.SVC(kernel='linear', verbose=True)\n",
        "SVM.fit(train_x,train_y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HddyY_hEtkVf",
        "outputId": "cbf3c929-01f9-4534-b9df-e3b48215fadc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Testing the model on the test set\n",
        "predictions_SVM = SVM.predict(test_x)\n",
        "print(\"SVM Accuracy Score (Validation) -> \",accuracy_score(predictions_SVM, test_y)*100)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score (Validation) ->  94.32911392405063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nI2K0jdtkM0"
      },
      "source": [
        "# Storing the models and tfidf for future usage in a pickle file.\n",
        "import pickle\n",
        "multi_model = {}\n",
        "\n",
        "tfidfs = {}\n",
        "models = {}\n",
        "\n",
        "tfidfs['outer_model'] = tfidf # Level-1 tfidf for outer classes\n",
        "models['outer_model'] = SVM # Level-1 model for outer classes\n",
        "\n",
        "multi_model['tfidfs'] = tfidfs\n",
        "multi_model['models'] = models\n",
        "\n",
        "# Update the model files into a file for future usage\n",
        "with open('/content/drive/Shared drives/ADA_assignment_2/A2_data/models/SVM_multimodel_4.pkl','wb') as f:\n",
        "    pickle.dump(multi_model,f)\n",
        "  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMQpv_S9mjYI"
      },
      "source": [
        "# Training the data points for every label building multiple Level-2 classifiers\n",
        "\n",
        "def train_SVM(temp_df, min_df, max_df, max_features, n_gram):\n",
        "  tfidf = TfidfVectorizer(encoding='utf-8',\n",
        "                          ngram_range= n_gram,\n",
        "                          stop_words=None,\n",
        "                          lowercase=False,\n",
        "                          max_df= max_df,\n",
        "                          min_df=min_df,\n",
        "                          max_features=max_features, \n",
        "                          norm='l2',\n",
        "                          sublinear_tf=True)\n",
        "\n",
        "  # Generate tfidf on the dataframe passed as input\n",
        "  tfidf_X = tfidf.fit_transform(temp_df['processed_abstract']).toarray()\n",
        "\n",
        "  train_x, test_x, train_y, test_y = train_test_split(tfidf_X, \n",
        "                                                    temp_df['label_id'],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=11)\n",
        "\n",
        "  np.random.seed(42)\n",
        "  SVM = svm.SVC(kernel='linear', verbose=False)\n",
        "  SVM.fit(train_x,train_y) # Fit the sub-label data with SVM\n",
        "\n",
        "  # The performance is tested on the test set\n",
        "  predictions_SVM = SVM.predict(test_x)\n",
        "  print(\"SVM Accuracy Score (Validation) -> \",accuracy_score(predictions_SVM, test_y)*100)\n",
        "\n",
        "  return(tfidf, SVM)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJMYnHWmnKtA",
        "outputId": "a0445aa0-241e-4ac7-995b-3f0e909b9df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The search for optimised parameters is performed in the final section of this notebook.\n",
        "# These parameters are optimised based on the data from every label for the best performance\n",
        "\n",
        "optimised_parameters = {\n",
        "    'math' : {'min_df' : 3, 'max_df' : 0.1, 'max_features' : 10000, 'n_gram' : (1,1)},\n",
        "    'q-fin' : {'min_df' : 15, 'max_df' : 0.5, 'max_features' :3000, 'n_gram' : (1,1)},\n",
        "    'cond-mat' : {'min_df' : 3, 'max_df' : 0.1, 'max_features' :3000, 'n_gram' : (1,1)},\n",
        "    'astro-ph' : {'min_df' : 3, 'max_df' : 0.5, 'max_features' :5000, 'n_gram' : (1,1)},\n",
        "    'q-bio' : {'min_df' : 10, 'max_df' : 0.4, 'max_features' :1000, 'n_gram' : (1,1)},\n",
        "    'physics' : {'min_df' : 3, 'max_df' : 0.3, 'max_features' :3000, 'n_gram' : (1,1)},\n",
        "    'stat' : {'min_df' : 7, 'max_df' : 0.2, 'max_features' :1000, 'n_gram' : (1,1)},\n",
        "    'nlin' : {'min_df' : 5, 'max_df' : 0.5, 'max_features' :1000, 'n_gram' : (1,1)}\n",
        "}\n",
        "optimised_parameters"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'astro-ph': {'max_df': 0.5,\n",
              "  'max_features': 5000,\n",
              "  'min_df': 3,\n",
              "  'n_gram': (1, 1)},\n",
              " 'cond-mat': {'max_df': 0.1,\n",
              "  'max_features': 3000,\n",
              "  'min_df': 3,\n",
              "  'n_gram': (1, 1)},\n",
              " 'math': {'max_df': 0.1, 'max_features': 10000, 'min_df': 3, 'n_gram': (1, 1)},\n",
              " 'nlin': {'max_df': 0.5, 'max_features': 1000, 'min_df': 5, 'n_gram': (1, 1)},\n",
              " 'physics': {'max_df': 0.3,\n",
              "  'max_features': 3000,\n",
              "  'min_df': 3,\n",
              "  'n_gram': (1, 1)},\n",
              " 'q-bio': {'max_df': 0.4,\n",
              "  'max_features': 1000,\n",
              "  'min_df': 10,\n",
              "  'n_gram': (1, 1)},\n",
              " 'q-fin': {'max_df': 0.5,\n",
              "  'max_features': 3000,\n",
              "  'min_df': 15,\n",
              "  'n_gram': (1, 1)},\n",
              " 'stat': {'max_df': 0.2, 'max_features': 1000, 'min_df': 7, 'n_gram': (1, 1)}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBUhCVuUzGIT",
        "outputId": "82d6dd10-9f79-4107-b46b-afb6b9a03451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Training Level-2 models\n",
        "for label, label_df in train_df2.items():\n",
        "  print(label, ' training...')\n",
        "\n",
        "  min_df_ = optimised_parameters[label]['min_df']\n",
        "  max_df_ = optimised_parameters[label]['max_df']\n",
        "  max_feat_ = optimised_parameters[label]['max_features']\n",
        "  n_gram_ = optimised_parameters[label]['n_gram']\n",
        "  \n",
        "  tfidf_inner, SVM_inner =  train_SVM(label_df, min_df_, max_df_, max_feat_, n_gram_) # Train the model with optimised parameters by calling the train_SVM() function\n",
        "\n",
        "  tfidfs[label] = tfidf_inner\n",
        "  models[label] = SVM_inner\n",
        "\n",
        "  # Models and TFIDF are stored for future usage\n",
        "  multi_model['tfidfs'] = tfidfs\n",
        "  multi_model['models'] = models\n",
        "\n",
        "# All the trained models and TFIDF are stored in a file for possible future usage\n",
        "with open('/content/drive/Shared drives/ADA_assignment_2/A2_data/models/SVM_multimodel_4.pkl','wb') as f:\n",
        "  pickle.dump(multi_model,f)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "math  training...\n",
            "SVM Accuracy Score (Validation) ->  63.54838709677419\n",
            "q-fin  training...\n",
            "SVM Accuracy Score (Validation) ->  57.009345794392516\n",
            "cond-mat  training...\n",
            "SVM Accuracy Score (Validation) ->  67.23404255319149\n",
            "astro-ph  training...\n",
            "SVM Accuracy Score (Validation) ->  80.6949806949807\n",
            "q-bio  training...\n",
            "SVM Accuracy Score (Validation) ->  65.97510373443983\n",
            "physics  training...\n",
            "SVM Accuracy Score (Validation) ->  65.28925619834712\n",
            "stat  training...\n",
            "SVM Accuracy Score (Validation) ->  53.96825396825397\n",
            "nlin  training...\n",
            "SVM Accuracy Score (Validation) ->  77.77777777777779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUaN0T_IqWel"
      },
      "source": [
        "# Classification on Original test submission file for Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAb0RGXUoxUH",
        "outputId": "4f65a625-6df9-4f46-f16a-3053c993a039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "test_df = pd.read_csv('/content/drive/Shared drives/ADA_assignment_2/A2_data/test_data.csv')\n",
        "test_df"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>the method of model averaging has become an im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>unmanned aerial vehicle (uav) systems are bein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>in this paper, we propose a new loss function ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>we show how to integrate a weak morphism of li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>caustics occur widely in dynamics and take on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7405</th>\n",
              "      <td>7406</td>\n",
              "      <td>statistical inference of evolutionary paramete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7406</th>\n",
              "      <td>7407</td>\n",
              "      <td>we present a deep learning framework based on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7407</th>\n",
              "      <td>7408</td>\n",
              "      <td>t-cell receptor (tcr) repertoire data contain ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7408</th>\n",
              "      <td>7409</td>\n",
              "      <td>in this paper, we provide a modern synthesis o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7409</th>\n",
              "      <td>7410</td>\n",
              "      <td>while the cms experiment is currently harvesti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7410 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      test_id                                           abstract\n",
              "0           1  the method of model averaging has become an im...\n",
              "1           2  unmanned aerial vehicle (uav) systems are bein...\n",
              "2           3  in this paper, we propose a new loss function ...\n",
              "3           4  we show how to integrate a weak morphism of li...\n",
              "4           5  caustics occur widely in dynamics and take on ...\n",
              "...       ...                                                ...\n",
              "7405     7406  statistical inference of evolutionary paramete...\n",
              "7406     7407  we present a deep learning framework based on ...\n",
              "7407     7408  t-cell receptor (tcr) repertoire data contain ...\n",
              "7408     7409  in this paper, we provide a modern synthesis o...\n",
              "7409     7410  while the cms experiment is currently harvesti...\n",
              "\n",
              "[7410 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSR5S2bUo9JA",
        "outputId": "44f22740-dec5-46dc-d473-71bc481ac334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Pre-process abstracts\n",
        "test_df['processed_abstract'] = preprocessing(test_df['abstract'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7410/7410 [00:51<00:00, 144.76it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQWKQHet1Y0-"
      },
      "source": [
        "# Load Level-1 model and TFIDF\n",
        "tfidf = multi_model['tfidfs']['outer_model']\n",
        "SVM = multi_model['models']['outer_model']\n",
        "\n",
        "# Transform the data with the tfidf of the Level-1 model\n",
        "tfidf_test = tfidf.transform(test_df['processed_abstract']).toarray()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17tWNnwF1ZJn",
        "outputId": "e389f340-a44a-4187-9475-2d63a92fe776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Make predictions with the Level-1 model and get the high-level classes\n",
        "outer_predictions = SVM.predict(tfidf_test)\n",
        "test_df['label'] = [id_to_label_outer[prediction] for prediction in outer_predictions] # Generate actual labels from predictions in a human-readable format\n",
        "test_df.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>abstract</th>\n",
              "      <th>processed_abstract</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>the method of model averaging has become an im...</td>\n",
              "      <td>method model average become important tool dea...</td>\n",
              "      <td>stat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>unmanned aerial vehicle (uav) systems are bein...</td>\n",
              "      <td>unmanned aerial vehicle uav system increasingl...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>in this paper, we propose a new loss function ...</td>\n",
              "      <td>paper propose new loss function call generaliz...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>we show how to integrate a weak morphism of li...</td>\n",
              "      <td>show integrate weak morphism lie algebra cross...</td>\n",
              "      <td>math</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>caustics occur widely in dynamics and take on ...</td>\n",
              "      <td>caustic occur widely dynamic take shape classi...</td>\n",
              "      <td>cond-mat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_id  ...     label\n",
              "0        1  ...      stat\n",
              "1        2  ...        cs\n",
              "2        3  ...        cs\n",
              "3        4  ...      math\n",
              "4        5  ...  cond-mat\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSj-ifGn2YBl",
        "outputId": "adbe43ff-30a6-433e-e8ff-ebc60e649164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "final_predictions = []\n",
        "\n",
        "# Use appropriate Level-2 models based on the predictions from the Level-1 model\n",
        "for ix, prediction in tqdm(enumerate(outer_predictions)):\n",
        "\n",
        "  # Skip if the Level-1 prediction is 'cs' since there are no further sub-classification\n",
        "  if id_to_label_outer[prediction] == 'cs':\n",
        "    final_predictions.append('cs')\n",
        "    # print('cs')\n",
        "    continue\n",
        "    \n",
        "  # Load Level-2 classifier model based on the Level-1 prediction\n",
        "  outer_lab = id_to_label_outer[prediction]\n",
        "  tfidf = multi_model['tfidfs'][outer_lab]\n",
        "  SVM = multi_model['models'][outer_lab]\n",
        "\n",
        "  # Predict the sub-class from the loaded TFIDF and the model\n",
        "  tfidf_inner = tfidf.transform([test_df.iloc[ix]['processed_abstract']]).toarray()\n",
        "  inner_prediction = SVM.predict(tfidf_inner)\n",
        "  inner_lab = id_to_label_inner[outer_lab][inner_prediction[0]] # Generate subclass label by indexing back into a label from a Label_ID\n",
        "\n",
        "  # print(outer_lab + '.' + inner_lab)\n",
        "  final_predictions.append(outer_lab + '.' + inner_lab) # Append the final predictions into a single prediction\n",
        "  "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7410it [01:16, 97.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eILmWbZ4mZE",
        "outputId": "bdf41eda-d592-46e9-e4a2-89e8194d9cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Load the predictions onto the test set\n",
        "test_df['label'] = final_predictions\n",
        "test_df.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>abstract</th>\n",
              "      <th>processed_abstract</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>the method of model averaging has become an im...</td>\n",
              "      <td>method model average become important tool dea...</td>\n",
              "      <td>stat.ME</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>unmanned aerial vehicle (uav) systems are bein...</td>\n",
              "      <td>unmanned aerial vehicle uav system increasingl...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>in this paper, we propose a new loss function ...</td>\n",
              "      <td>paper propose new loss function call generaliz...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>we show how to integrate a weak morphism of li...</td>\n",
              "      <td>show integrate weak morphism lie algebra cross...</td>\n",
              "      <td>math.AT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>caustics occur widely in dynamics and take on ...</td>\n",
              "      <td>caustic occur widely dynamic take shape classi...</td>\n",
              "      <td>cond-mat.quant-gas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_id  ...               label\n",
              "0        1  ...             stat.ME\n",
              "1        2  ...                  cs\n",
              "2        3  ...                  cs\n",
              "3        4  ...             math.AT\n",
              "4        5  ...  cond-mat.quant-gas\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdGbrQ8y49fS"
      },
      "source": [
        "# Save the file to upload and check the model performance\n",
        "test_df[['test_id', 'label']].to_csv('/content/drive/Shared drives/ADA_assignment_2/A2_data/Predictions/svc_multi_predictions_v5.csv', index = False)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQNM7XSQs8La"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcuTMTo0s9zC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPOvR09Vs_ZD"
      },
      "source": [
        "# Supplementary Code\n",
        "```This is the end of the main content of the notebook. The subsequent sections contain the supporting code pertaining to other supplementary tasks```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ee7A5tLkK5G"
      },
      "source": [
        "### Data augmentation attempt\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1hjVi7bkKVT"
      },
      "source": [
        "# train_df_aug = pd.read_csv('/content/drive/Shared drives/ADA_assignment_2/A2_data/clean_balanced_train_data.csv', usecols = ['label', 'abstract']) # If augmenting data for balanced labels\n",
        "shortlisted_df = pd.DataFrame(columns = ['label', 'abstract'])\n",
        "limit_per_class = 250 # Decide upon a count for all the calsses\n",
        "\n",
        "for ix, row in df1.iterrows():\n",
        "\n",
        "  label = row['index']\n",
        "  count = row['label']\n",
        "\n",
        "  if count > limit_per_class: # Sample randomly when there are more observations --> UNDER_SAMPLING\n",
        "    temp_df = train_df[train_df['label'] == label]\n",
        "    temp_df = temp_df.sample(n = limit_per_class)\n",
        "\n",
        "    shortlisted_df = pd.concat([shortlisted_df, temp_df])\n",
        "  else: # Borrow data from the augmented data if the samples are less in number --> OVER_SAMPLING\n",
        "    temp_df = train_df[train_df['label'] == label]\n",
        "    shortlisted_df = pd.concat([shortlisted_df, temp_df])\n",
        "\n",
        "    temp_df = train_df_aug[train_df_aug['label'] == label]\n",
        "    temp_df = temp_df.sample(n = (limit_per_class - count))\n",
        "    shortlisted_df = pd.concat([shortlisted_df, temp_df])\n",
        "\n",
        "train_df = shortlisted_df.sample(frac=1).reset_index(drop=True) # Shuffle data completely\n",
        "print(train_df.shape[0])\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MNiLCuplotb"
      },
      "source": [
        "### Testing for optimum parameters for all the Level 2 classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqBLy7rqlr9E"
      },
      "source": [
        "#TFIDF\n",
        "def train_SVM(temp_df, min_df, max_df, max_features, n_grams):\n",
        "  tfidf = TfidfVectorizer(encoding='utf-8',\n",
        "                          ngram_range=n_grams,\n",
        "                          stop_words=None,\n",
        "                          lowercase=False,\n",
        "                          max_df=max_df,\n",
        "                          min_df=min_df,\n",
        "                          max_features=max_features, \n",
        "                          norm='l2',\n",
        "                          sublinear_tf=True)\n",
        "\n",
        "  tfidf_X = tfidf.fit_transform(temp_df['processed_abstract']).toarray()\n",
        "\n",
        "  train_x, test_x, train_y, test_y = train_test_split(tfidf_X, \n",
        "                                                    temp_df['label_id'],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=11)\n",
        "\n",
        "  np.random.seed(42)\n",
        "  SVM = svm.SVC(kernel='linear', verbose=False)\n",
        "  SVM.fit(train_x,train_y)\n",
        "\n",
        "  predictions_SVM = SVM.predict(test_x)\n",
        "  accuracy = accuracy_score(predictions_SVM, test_y)*100\n",
        "  # print(\"SVM Accuracy Score (Validation) -> \", accuracy)\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36CMjjhdmceR"
      },
      "source": [
        "outer_label = 'stat'\n",
        "temp_df = train_df2[outer_label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9yZFAfxmzFS",
        "outputId": "096b0bc6-9ebc-41cb-8baf-fc6abbb869a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_SVM(temp_df, 10, 0.3, 3000, (1,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48.41269841269841"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzLFLbgPmXm5",
        "outputId": "d208de7e-4b57-4764-9baf-8b3d3c64809c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "acc_df = pd.DataFrame(columns = ['min_df', 'max_df', 'max_features', 'n_gram', 'accuracy'])\n",
        "df_ix = 0\n",
        "\n",
        "min_dfs = [1, 2,5,8,10,12,15,17,20, 25]\n",
        "max_dfs = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
        "max_features = [1000, 3000, 5000, 10000, 15000, 20000, 25000, 30000]\n",
        "n_grams = [(1,1), (1,2), (1,3)]\n",
        "\n",
        "for min_ in tqdm(min_dfs):\n",
        "  for max_ in max_dfs:\n",
        "    for max_feat_ in max_features:\n",
        "      for gram in n_grams:\n",
        "        try:\n",
        "          acc = train_SVM(temp_df, min_, max_, max_feat_, gram)\n",
        "          acc_df.loc[df_ix] = [min_, max_, max_feat_, gram, acc]\n",
        "        except:\n",
        "          acc_df.loc[df_ix] = [min_, max_, max_feat_, gram, 0.0]\n",
        "        df_ix += 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [22:48<3:25:14, 1368.23s/it]\u001b[A\n",
            " 20%|██        | 2/10 [34:08<2:34:54, 1161.83s/it]\u001b[A\n",
            " 30%|███       | 3/10 [38:18<1:43:38, 888.29s/it] \u001b[A\n",
            " 40%|████      | 4/10 [41:15<1:07:28, 674.83s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [43:48<43:12, 518.45s/it]  \u001b[A\n",
            " 60%|██████    | 6/10 [46:02<26:52, 403.04s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [47:56<15:48, 316.22s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [49:41<08:25, 252.85s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [51:14<03:24, 204.88s/it]\u001b[A\n",
            "100%|██████████| 10/10 [52:33<00:00, 315.37s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQS2cyIBmX4E",
        "outputId": "390bb3cb-8ae8-45c7-ff75-fe88c6444423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "acc_df = acc_df.sort_values(['accuracy'], ascending = False).reset_index()\n",
        "max_val = max(acc_df['accuracy'])\n",
        "acc_df = acc_df[acc_df['accuracy'] == max_val].sort_values(['max_features', 'min_df', 'max_df', 'n_gram'], ascending = [True, True, True, True])\n",
        "acc_df.to_csv('/content/drive/Shared drives/ADA_assignment_2/A2_data/hyperparameter_data/' + outer_label + '_inner.csv', index = False)\n",
        "acc_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>min_df</th>\n",
              "      <th>max_df</th>\n",
              "      <th>max_features</th>\n",
              "      <th>n_gram</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>364</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>3000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>388</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>412</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>367</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>391</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>415</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>370</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>10000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>394</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>10000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>418</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>373</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>397</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>421</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>376</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>20000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>400</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>20000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>424</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>379</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>25000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>403</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>25000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>427</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>382</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>30000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>406</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>30000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>430</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>54.761905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index min_df  max_df max_features  n_gram   accuracy\n",
              "2     364      5     0.7         3000  (1, 2)  54.761905\n",
              "9     388      5     0.9         3000  (1, 2)  54.761905\n",
              "20    412      5     1.0         3000  (1, 2)  54.761905\n",
              "3     367      5     0.7         5000  (1, 2)  54.761905\n",
              "10    391      5     0.9         5000  (1, 2)  54.761905\n",
              "16    415      5     1.0         5000  (1, 2)  54.761905\n",
              "4     370      5     0.7        10000  (1, 2)  54.761905\n",
              "11    394      5     0.9        10000  (1, 2)  54.761905\n",
              "18    418      5     1.0        10000  (1, 2)  54.761905\n",
              "5     373      5     0.7        15000  (1, 2)  54.761905\n",
              "14    397      5     0.9        15000  (1, 2)  54.761905\n",
              "15    421      5     1.0        15000  (1, 2)  54.761905\n",
              "6     376      5     0.7        20000  (1, 2)  54.761905\n",
              "12    400      5     0.9        20000  (1, 2)  54.761905\n",
              "19    424      5     1.0        20000  (1, 2)  54.761905\n",
              "7     379      5     0.7        25000  (1, 2)  54.761905\n",
              "13    403      5     0.9        25000  (1, 2)  54.761905\n",
              "17    427      5     1.0        25000  (1, 2)  54.761905\n",
              "8     382      5     0.7        30000  (1, 2)  54.761905\n",
              "1     406      5     0.9        30000  (1, 2)  54.761905\n",
              "0     430      5     1.0        30000  (1, 2)  54.761905"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcazqw-Z2z64"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}